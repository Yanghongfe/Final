{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T16:18:33.073547Z",
     "start_time": "2024-05-02T16:18:33.037295300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing import sequence\n",
    "df = pd.read_csv('features_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "NGRAMS = (2, 3)\n",
    "vect = CountVectorizer(analyzer='char', max_df=0.3, min_df=10, ngram_range=NGRAMS, lowercase=False) \n",
    "a = vect.fit_transform(df.name)\n",
    "vocab = vect.vocabulary_\n",
    "words = []\n",
    "for b in vocab:\n",
    "    c = vocab[b]\n",
    "    words.append((a[:, c].sum(), b))\n",
    "words = sorted(words, reverse=True)\n",
    "words_list = [w[1] for w in words]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T16:18:48.261761200Z",
     "start_time": "2024-05-02T16:18:33.670462900Z"
    }
   },
   "id": "167410dbe40859fb",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('words_list.pkl', 'wb') as f:\n",
    "    pickle.dump(words_list, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T16:18:53.974283200Z",
     "start_time": "2024-05-02T16:18:53.967771900Z"
    }
   },
   "id": "866608771efed63a",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def n_grams(tokens, n=1):\n",
    "    \"\"\"\n",
    "    Generate n-grams from a sequence of tokens by breaking down the process into individual steps.\n",
    "\n",
    "    Args:\n",
    "        tokens (list): The list of tokens from which to generate n-grams.\n",
    "        n (int): The size of each n-gram.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing n-grams as tuples.\n",
    "    \"\"\"\n",
    "    n_grams_list = []  \n",
    "    total_n_grams = len(tokens) - n + 1\n",
    "    for i in range(total_n_grams):\n",
    "        n_gram = tuple(tokens[i:i + n])  \n",
    "        n_grams_list.append(n_gram)  \n",
    "    return n_grams_list\n",
    "\n",
    "def range_ngrams(tokens, ngram_range=(1, 2)):\n",
    "    \"\"\"\n",
    "    Generate all n-grams for each 'n' within the specified range from a list of tokens.\n",
    "\n",
    "    Args:\n",
    "        tokens (list): The list of tokens from which to generate n-grams.\n",
    "        ngram_range (tuple): A tuple specifying the minimum and maximum n-gram sizes.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing all n-grams across the specified range.\n",
    "    \"\"\"\n",
    "    all_ngrams = []\n",
    "    for n in range(ngram_range[0], ngram_range[1] + 1):\n",
    "        ngrams_for_n = n_grams(tokens, n) \n",
    "        all_ngrams.extend(ngrams_for_n)  \n",
    "    return all_ngrams\n",
    "\n",
    "\n",
    "def find_ngrams(text, ngrams_range):\n",
    "    \"\"\"\n",
    "    Find the index positions of n-grams from a token list in a global 'words_list'.\n",
    "\n",
    "    Args:\n",
    "        text (list): List of tokens from which n-grams will be generated.\n",
    "        ngrams_range (tuple): Tuple indicating the minimum and maximum sizes of n-grams to generate.\n",
    "\n",
    "    Returns:\n",
    "        list: List of indices from 'words_list' where each n-gram can be found, or 0 if not found.\n",
    "    \"\"\"\n",
    "    a = range_ngrams(text, ngrams_range)\n",
    "    wi = []\n",
    "    for i in a:\n",
    "        w = ''.join(i)\n",
    "        try:\n",
    "            idx = words_list.index(w)\n",
    "        except:\n",
    "            idx = 0\n",
    "        wi.append(idx)\n",
    "    return wi\n",
    "\n",
    "\n",
    "def is_vowel(c):\n",
    "    c = c.lower()\n",
    "    v_set = list('aeiou')\n",
    "    if c in v_set:\n",
    "        return 1\n",
    "    return 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T16:18:54.488844500Z",
     "start_time": "2024-05-02T16:18:54.484766800Z"
    }
   },
   "id": "f48b59f20c6b9c0b",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('words_list.pkl', 'rb') as f:\n",
    "    words_list = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T16:18:55.073533700Z",
     "start_time": "2024-05-02T16:18:55.069449500Z"
    }
   },
   "id": "6358e1222d8c5eab",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_ngram_data = np.array(df.name.apply(lambda c: find_ngrams(c, NGRAMS)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T16:19:00.097170200Z",
     "start_time": "2024-05-02T16:18:55.618408500Z"
    }
   },
   "id": "29b5c0ff73068467",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_feature = df[['length', 'fl_is_v', 'll_is_v']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T16:19:02.648555900Z",
     "start_time": "2024-05-02T16:19:02.637105100Z"
    }
   },
   "id": "2c20f4fb0dcb2607",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(41376, 3)\n",
      "(41376, 25)\n",
      "(41376, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[ 40, 142,  89, ...,  14,   0,   0],\n       [  0,   0,   0, ...,   8,   0,   0],\n       [  0,   0,   0, ...,  10,   0,   1],\n       ...,\n       [ 10, 193,  93, ...,  15,   0,   0],\n       [  0,   0,   0, ...,  11,   0,   1],\n       [  0,   0,   0, ...,  12,   0,   0]])"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ngram_data = sequence.pad_sequences(X_ngram_data, maxlen=25)\n",
    "X_feature_list = X_feature.values.tolist()\n",
    "X_feature_list = np.array(X_feature_list)\n",
    "print(type(X_ngram_data))\n",
    "print(type(X_feature_list))\n",
    "print(X_feature_list.shape)\n",
    "print(X_ngram_data.shape)\n",
    "final_feature = np.hstack((X_ngram_data, X_feature_list))\n",
    "print(final_feature.shape)\n",
    "final_feature"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T16:19:05.353123700Z",
     "start_time": "2024-05-02T16:19:05.281719400Z"
    }
   },
   "id": "d11bb4e8a8d9b886",
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "91c1a1d40a89f6f9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final_feature)\n",
    "df2 = pd.DataFrame(X_ngram_data)\n",
    "\n",
    "df.to_csv('deeplearning_features.csv', index=False)\n",
    "df2.to_csv('deeplearning_ngram_features.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T16:19:07.689766500Z",
     "start_time": "2024-05-02T16:19:07.462242700Z"
    }
   },
   "id": "5f16ad9dc74ce3d3",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(41376, 28)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_feature.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T16:19:08.320680Z",
     "start_time": "2024-05-02T16:19:08.316367500Z"
    }
   },
   "id": "f06f45ecdacaf336",
   "execution_count": 53
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
